{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index:\n",
    "1. Load all data from database and save a dump\n",
    "\n",
    "    1.1 Load from the database\n",
    "    \n",
    "    1.2 Dump the data\n",
    "    \n",
    "    1.3 Simple function to either load the dump or fetch from db\n",
    "\n",
    "\n",
    "2. Build mouse models\n",
    "\n",
    "    2.1 Add new models\n",
    "    \n",
    "    2.2 Combine new models\n",
    "    \n",
    "        2.2.1 Add new features:\n",
    "            \n",
    "            \n",
    "    \n",
    "    2.3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect the data logs from the database\n",
    "from pymongo import MongoClient\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_participants(method='db', dump=False):\n",
    "    if method == 'dump':\n",
    "        with open('valid_participants', 'rb') as f:\n",
    "            try:\n",
    "                pickle.load(f)\n",
    "            except:\n",
    "                return \"It seems you did't dump the dataset in the first place\"\n",
    "        return pickle.load(f)\n",
    "        \n",
    "    connection = MongoClient('mongodb://dave123:awesomeGuy@localhost:27017') #Yeah I can hear you ;)\n",
    "    db = connection.passauth\n",
    "    collection_names = db.collection_names()\n",
    "    participants = [list(db[user].find()) for user in collection_names \n",
    "                        if all([True if 'mouseMeta' in session.keys() else False for session in list(db[user].find())])]\n",
    "    valid_participants = [participant for participant in participants if len(participant) >= 25]\n",
    "\n",
    "    if dump:\n",
    "        with open('valid_participants', 'wb') as f:\n",
    "            pickle.dump(valid_participants, f)\n",
    "        \n",
    "    return valid_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "connection = MongoClient('localhost:27017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "attackers = []\n",
    "for each in connection['passauth-attack'].collection_names():\n",
    "    attackers.append([_ for _ in connection['passauth-attack'][each].find()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('attackers', 'wb') as f:\n",
    "    pickle.dump(attackers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "valid_participants = get_valid_participants(dump=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mouse Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, userid, mouseLogs, keyLogs):\n",
    "        self.userid = userid\n",
    "        self.mouseLogs = np.array(mouseLogs)\n",
    "        self.keyLogs = np.array(keyLogs)\n",
    "        \n",
    "def pad_trim(data, size=100, padding_method='zeros'):\n",
    "    \"\"\"\n",
    "    max_len: the size of the final list\n",
    "    padding_method:\n",
    "        'zeros': adds zeros (0) for missing numeric values\n",
    "        'last': duplicates last value\n",
    "        'interpolated': interpolatest the values\n",
    "    \"\"\"\n",
    "   \n",
    "    if len(data) == 0:\n",
    "        pass\n",
    "   \n",
    "    elif len(data) > size:\n",
    "        data = data[:size]\n",
    "   \n",
    "    else:\n",
    "        if padding_method == 'zeros':\n",
    "            padding = np.tile(np.array([0]*len(data[0])), reps=(size-len(data), 1))\n",
    "            data = np.vstack([data, padding])\n",
    "           \n",
    "    return data\n",
    "\n",
    "def pick_n(data, n):\n",
    "    \"\"\"\n",
    "    pick only n-th rows\n",
    "    \"\"\"\n",
    "    return data[::n]\n",
    "\n",
    "flip = np.flip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "for _, user in enumerate(valid_participants):\n",
    "    mouseLogs = [np.array(session['mouseLogs'][0], dtype='int32') for session in user]\n",
    "    keyLogs = [np.array(list(map(lambda x: x['duration'], session['passwordLogs']+session['usernameLogs'])), dtype='int32') \n",
    "               for session in user]\n",
    "    if all([len(mouseLog) for mouseLog in mouseLogs]):\n",
    "        users.append(User(_+1, mouseLogs, keyLogs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(actual, prediction):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    assert len(actual) == len(prediction), \"Array lengths do not match\"\n",
    "    for i in range(len(actual)): \n",
    "        if actual[i]==1:\n",
    "            if prediction[i]==1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        elif actual[i]==0:\n",
    "            if prediction[i]==0:\n",
    "                tn += 1\n",
    "            if prediction[i]==1:\n",
    "                fp += 1\n",
    "                \n",
    "    assert tp+fp+tn+fn == len(actual), \"Class labels should be binary (1 or 0)\"\n",
    "    return(tp, fp, tn, fn)\n",
    "\n",
    "def interpret_perf(tp, fp, tn, fn):\n",
    "#     print(\"True Positive: \", tp)\n",
    "#     print(\"False Positive: \", fp)\n",
    "#     print(\"True Negative: \", tn)\n",
    "#     print(\"False Negative: \", fn)\n",
    "#     print(\"TPR: \", tp/(tp+fn))\n",
    "    res = [fp/(fp+tn) if (fp+tn) != 0 else 0, #FAR\n",
    "           fn/(tp+fn) if (tp+fn) !=0 else 0,\n",
    "           (tp+tn)/(tp+tn+fp+fn) if (tp+tn+fp+fn) !=0 else 0]\n",
    "\n",
    "    return res\n",
    "        \n",
    "def classifier_summary(actual, prediction):\n",
    "    return interpret_perf(*perf_measure(actual, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "data_logger = logging.getLogger('DATA')\n",
    "learning_logger = logging.getLogger('LEARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MouseDataModel:\n",
    "    def __init__(self, userid, users):\n",
    "        self.userid = userid\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "        self.X_test = None\n",
    "        self.Y_test = None\n",
    "\n",
    "        dataX = []\n",
    "        dataY = []\n",
    "        dataXother = []\n",
    "        dataYother = []\n",
    "        \n",
    "        for user in users: #dataX is a collection of users\n",
    "            if user.userid == self.userid:\n",
    "                for mouseLog in user.mouseLogs:\n",
    "                    dataX.append(mouseLog)\n",
    "                    dataY.append(user.userid)\n",
    "            else:\n",
    "                for mouseLog in user.mouseLogs:\n",
    "                    dataXother.append(mouseLog)\n",
    "                    dataYother.append(user.userid)\n",
    "                    \n",
    "                    \n",
    "        self.meanSessionLength = int(np.mean([len(x) for x in dataX]) + \n",
    "                                     np.std([len(x) for x in dataX]))\n",
    "        \n",
    "        \n",
    "        self.dataX = np.array(dataX)\n",
    "        self.dataY = np.array(dataY)\n",
    "        self.dataXother = np.array(dataXother)\n",
    "        self.dataYother = np.array(dataYother)\n",
    "        \n",
    "    def train_test_data(self, \n",
    "                        test_size=(0.20, 0.50), \n",
    "                        classes=0, \n",
    "                        binary_classes=False, \n",
    "                        instances=5, \n",
    "                        total_classes=None,\n",
    "                        random=3):\n",
    "        \"\"\"\n",
    "        Return and set training and test dataset for self\n",
    "        \n",
    "        Keyword Arguments:\n",
    "        test_size (float, float): test size for splitting the dataset of self vs other classes.\n",
    "        classes (int): Number of other user MouseDataModel(s) to consider.\n",
    "        instances (int): Number of examples to take from the considered classes.\n",
    "        \n",
    "        \"\"\"     \n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = \\\n",
    "            train_test_split(self.dataX, self.dataY, test_size=test_size[0], random_state=random)\n",
    "        \n",
    "        if classes == 0:\n",
    "            self.X_train, self.X_test, self.Y_train, self.Y_test = \\\n",
    "                X_train, X_test, Y_train, Y_test\n",
    "            \n",
    "        elif classes > 0:\n",
    "            assert instances <= 25, \"Too many instances requested\"\n",
    "            other_classes = np.unique(self.dataYother[self.dataYother != self.userid])\n",
    "            assert len(other_classes) >= classes, \"Too many classes\"\n",
    "            \n",
    "            np.random.shuffle(other_classes)\n",
    "            other_classes = other_classes[:classes]\n",
    "            data_logger.info(\"Selected classes \"+str(other_classes))\n",
    "            dataX = []\n",
    "            dataY = []\n",
    "\n",
    "            for each in other_classes:\n",
    "                for log in self.dataXother[self.dataYother == each][:instances]:\n",
    "                    dataX.append(log)\n",
    "                    if binary_classes:\n",
    "                        dataY.append(-1)\n",
    "                    else:\n",
    "                        dataY.append(each)\n",
    "\n",
    "            X_train_other, X_test_other, Y_train_other, Y_test_other = \\\n",
    "                train_test_split(np.array(dataX), np.array(dataY), test_size=test_size[1], random_state=random)\n",
    "\n",
    "            self.X_train = np.concatenate((X_train, X_train_other), axis=0)\n",
    "            self.X_test = np.concatenate((X_test, X_test_other), axis=0)\n",
    "            self.Y_train = np.concatenate((Y_train, Y_train_other), axis=0)\n",
    "            self.Y_test = np.concatenate((Y_test, Y_test_other), axis=0)\n",
    "        \n",
    "            #Shuffle the data rows\n",
    "            assert len(self.X_test) == len(self.Y_test)\n",
    "            p = np.random.permutation(len(self.X_test))\n",
    "            self.X_test = self.X_test[p]\n",
    "            self.Y_test = self.Y_test[p]\n",
    "            \n",
    "        \n",
    "        return self.X_train, self.X_test, self.Y_train, self.Y_test #other_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Model for single user:\n",
    "class MouseLearningModel:\n",
    "    def __init__(self, X_train, X_test, Y_train, Y_test, meanMouseSessionLength=100):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "        self.ensemble = None\n",
    "\n",
    "        self.data_transformations = [\n",
    "            lambda x: pad_trim(flip(x, axis=0), size=50)[:, 0:1].flatten(),\n",
    "            lambda x: pad_trim(flip(x, axis=0), size=50)[:, 1:2].flatten(),\n",
    "            lambda x: pad_trim(x, size=50)[:, 0:1].flatten(),\n",
    "            lambda x: pad_trim(x, size=50)[:, 1:2].flatten(),\n",
    "            lambda x: pad_trim(x[:5], size=50)[:, 0:2].flatten(),\n",
    "            lambda x: pad_trim(x, size=meanMouseSessionLength)[:, 0:2].flatten(),\n",
    "            lambda x: pad_trim(np.abs(x-x[0]))[:, 0:2].flatten(),\n",
    "            lambda x: pad_trim(np.abs(np.multiply(x-x[0], np.log(x[:,2:]))))[:, 0:2].flatten(),\n",
    "            #PCA\n",
    "        ]\n",
    "\n",
    "        self.learning_models = [\n",
    "            {\"algorithm\": SVC,\n",
    "             \"params\": [\n",
    "                 {'kernel':'linear', 'gamma':'auto', 'degree':3, 'class_weight':'balanced', 'cache_size':10}\n",
    "             ]},\n",
    "            {\"algorithm\": AdaBoostClassifier, \n",
    "             \"params\": [\n",
    "                 {'n_estimators':100},\n",
    "             ]},\n",
    "            {\"algorithm\": GaussianNB},\n",
    "            {\"algorithm\": RandomForestClassifier,\n",
    "             \"params\": [\n",
    "                 {'n_estimators': 20},\n",
    "             ]},\n",
    "            {\"algorithm\": BernoulliNB},\n",
    "            {\"algorithm\": MultinomialNB},\n",
    "            {\"algorithm\": SGDClassifier},\n",
    "            {\"algorithm\": MLPClassifier,\n",
    "             \"params\": [\n",
    "                 {'max_iter': 1000},\n",
    "             ]},\n",
    "        ]\n",
    "        \n",
    "        self.ideal_cutoff = None\n",
    "        self.ideal_models = None\n",
    "        \n",
    "\n",
    "    def approximate_cutoffs(self, models, tolerance=0.1, iterations=7):\n",
    "        \n",
    "        ideal_cutoff = 0\n",
    "        best_far = sorted(list(filter(lambda x: not x[-1][1] >0.9, models)), key=lambda x: x[-1][0])[0:7]\n",
    "        best_frr = sorted(list(filter(lambda x: not x[-1][0] >0.5, models)), key=lambda x: x[-1][1])[0:5]\n",
    "        self.ideal_models = best_far + best_frr\n",
    "        ideal_cutoffs = []\n",
    "        for i in range(iterations):\n",
    "            res = self.cutoff_score(self.ideal_models) #is continuous \n",
    "            res = sorted(res, key= lambda x: x[1][-1])\n",
    "            ideal_cutoffs = ideal_cutoffs + list(filter(lambda x: abs(x[-1][-1] - res[-1][-1][-1]) < tolerance, res))\n",
    "        \n",
    "        self.ideal_cutoff=8\n",
    "        return ideal_cutoffs\n",
    "        \n",
    "    def cutoff_score(self, models):\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        X_train_, X_validation_, Y_train_, Y_validation_ = \\\n",
    "                            train_test_split(self.X_train, self.Y_train)\n",
    "\n",
    "        for model in models:\n",
    "            X_train_transformed = np.array([self.data_transformations[model[2]](_) for _ in X_train_])\n",
    "            X_validation_transformed = np.array([self.data_transformations[model[2]](_) for _ in X_validation_])\n",
    "            model = model[0].fit(X_train_transformed, Y_train_)\n",
    "            predictions.append(model.predict(X_validation_transformed))\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        predictions = np.sum(predictions, axis=0)\n",
    "        \n",
    "        cutoff_performances = []\n",
    "        for i in range(1, len(models)):\n",
    "            cutoff_performances.append((i, classifier_summary(Y_validation_, np.where(predictions>i, 1, 0))))\n",
    "        return cutoff_performances\n",
    "\n",
    "        \n",
    "    def optimal_models(self):\n",
    "\n",
    "        model_performances = []\n",
    "        for learning_model in self.learning_models:\n",
    "            learning_logger.info(\"Running \" + learning_model['algorithm'].__name__)\n",
    "            \n",
    "            for params_index, params in enumerate(learning_model.get('params', [{}])):\n",
    "                \n",
    "                transformation_performances = {}\n",
    "                \n",
    "                for _, transformation in enumerate(self.data_transformations):\n",
    "                    validation_performance = []\n",
    "                    model = learning_model['algorithm'](**params)\n",
    "                    for iteration in range(5):\n",
    "                        \n",
    "                        X_train_transformed = np.array([transformation(_) for _ in self.X_train])\n",
    "                        X_test_transformed = np.array([transformation(_) for _ in self.X_test])\n",
    "\n",
    "                        X_train_transformed, X_validation_transformed, Y_train_, Y_validation_ = \\\n",
    "                            train_test_split(X_train_transformed, self.Y_train)\n",
    "\n",
    "                        model.fit(X_train_transformed, Y_train_)\n",
    "                        validation_performance.append(classifier_summary(Y_validation_, model.predict(X_validation_transformed)))\n",
    "\n",
    "                    transformation_performances[_] = np.array(validation_performance).mean(axis=0)\n",
    "\n",
    "                    model_performances.append((model, \n",
    "                                              params_index,\n",
    "                                               _,\n",
    "                                              np.array(validation_performance).mean(axis=0)))\n",
    "            \n",
    "        return model_performances\n",
    "        \n",
    "    def cross_validate(self, model, X_train, Y_train):\n",
    "        p = np.random.permutation(len(Y_train)//2)\n",
    "        return Y_train[p], model.predict(X_train[p])\n",
    "\n",
    "    def train(self):\n",
    "        assert not self.ideal_models is None, \"Ideal cutoff not set, check if approximate_cutoff has been run\"\n",
    "        ensemble = []\n",
    "        if not self.X_train is None and not self.Y_train is None:\n",
    "            for model in self.ideal_models:\n",
    "                X_train_transformed = np.array([self.data_transformations[model[2]](_) for _ in self.X_train])\n",
    "                _model = model[0].fit(X_train_transformed, self.Y_train)\n",
    "                ensemble.append((deepcopy(_model), model[2]))\n",
    "            \n",
    "        self.ensemble = ensemble\n",
    "        return True\n",
    "\n",
    "    def test(self, ideal_cutoff=None):\n",
    "        assert not self.ensemble is None, \"Ensemble not found\"\n",
    "        if ideal_cutoff is None:\n",
    "            ideal_cutoff = self.ideal_cutoff\n",
    "        predictions = []\n",
    "        for model in self.ensemble:\n",
    "            X_test_transformed = np.array([self.data_transformations[model[1]](_) for _ in self.X_test])\n",
    "            predictions.append(model[0].predict(X_test_transformed))\n",
    "        predictions = np.sum(np.array(predictions), axis=0)\n",
    "\n",
    "        return predictions, classifier_summary(self.Y_test, np.where(predictions > ideal_cutoff, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystrokeLearningModel:\n",
    "    def __init__(self, X_train, X_test, Y_train, Y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "        self.ideal_models = None\n",
    "        self.ensemble = None\n",
    "        \n",
    "        userKeyLogs = [[np.min(_), np.max(_)] for _ in self.X_train]\n",
    "        userKeyLogsMinMax = tuple(np.mean(userKeyLogs, axis=0))\n",
    "        \n",
    "        self.data_transformations = [\n",
    "            lambda x: np.array([np.histogram(keyLog, \n",
    "                                             bins=np.histogram(userKeyLogs, bins=50, range=userKeyLogsMinMax)[1])[0] \n",
    "                                for keyLog in x]),\n",
    "            lambda x: np.array([np.histogram(keyLog, \n",
    "                                 bins=np.histogram(userKeyLogs, bins=50, range=userKeyLogsMinMax)[1])[0] \n",
    "                    for keyLog in x]),\n",
    "        ]\n",
    "\n",
    "        self.learning_models = [\n",
    "            {\"algorithm\": SVC,\n",
    "             \"params\": [\n",
    "                 {'kernel':'linear', 'gamma':'auto', 'degree':3, 'class_weight':'balanced', 'cache_size':10}\n",
    "             ]},\n",
    "            {\"algorithm\": AdaBoostClassifier, \n",
    "             \"params\": [\n",
    "                 {'n_estimators':100},\n",
    "             ]},\n",
    "            {\"algorithm\": GaussianNB},\n",
    "            {\"algorithm\": RandomForestClassifier,\n",
    "             \"params\": [\n",
    "                 {'n_estimators': 20},\n",
    "             ]},\n",
    "            {\"algorithm\": BernoulliNB},\n",
    "            {\"algorithm\": MultinomialNB},\n",
    "            {\"algorithm\": SGDClassifier},\n",
    "            {\"algorithm\": MLPClassifier,\n",
    "             \"params\": [\n",
    "                 {'max_iter': 1000},\n",
    "             ]},\n",
    "        ]\n",
    "        \n",
    "    def optimal_models(self, iterations=5):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.X_train, self.Y_train, test_size=0.2)\n",
    "        res = []\n",
    "        for i in range(iterations):\n",
    "            for learning_model in self.learning_models:\n",
    "                for params_index, params in enumerate(learning_model.get('params', [{}])):\n",
    "                    for _, transformation in enumerate(self.data_transformations):\n",
    "                        model = learning_model['algorithm'](**params)\n",
    "                        model.fit(transformation(X_train), Y_train)\n",
    "                        res.append((model, params_index, _, classifier_summary(Y_test, model.predict(transformation(X_test)))))\n",
    "        \n",
    "        ideal_models = sorted(filter(lambda x: x[-1][1] <=0.7, res), key = lambda x: (x[-1][0], -1*x[-1][-1]))\n",
    "        self.ideal_models = ideal_models[:10]\n",
    "        return self.ideal_models\n",
    "    \n",
    "    def train(self, iterations=5):\n",
    "        if self.ideal_models is None:\n",
    "            self.optimal_models(self.X_train, self.X_test, self.Y_train, self.Y_test, iterations=iterations)\n",
    "        \n",
    "        ensemble = []\n",
    "        for model in self.ideal_models:\n",
    "            ensemble.append((deepcopy(model[0].fit(self.data_transformations[model[2]](self.X_train), self.Y_train)), \n",
    "                            model[2]))\n",
    "        \n",
    "        self.ensemble = ensemble\n",
    "        return True\n",
    "    \n",
    "    def test(self, ideal_cutoff=7, display_prediction=True):\n",
    "        assert not self.ensemble is None, \"Ensemble not calculated\"\n",
    "        predictions = []\n",
    "        for model in self.ensemble:\n",
    "            predictions.append(model[0].predict(self.data_transformations[model[1]](self.X_test)))\n",
    "            \n",
    "        predictions = np.sum(np.array(predictions), axis=0)\n",
    "        if display_prediction:\n",
    "            print(predictions)\n",
    "            print(np.where(predictions > ideal_cutoff, 1, 0))\n",
    "        return predictions, classifier_summary(self.Y_test, np.where(predictions > ideal_cutoff, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Authenticator:\n",
    "    def __init__(self, userid, sessions, classes=5, test_size=(0.20, 0.50), instances=5):\n",
    "        self.user = UserModel(userid, sessions)\n",
    "        self.user.train_test_data(classes=classes, test_size=test_size, instances=instances)       \n",
    "        \n",
    "        self.mouse_params = list(self.user.mouse_train_test_data())+[self.user.meanMouseLength]\n",
    "        self.mouseLearningModel = MouseLearningModel(*self.mouse_params)\n",
    "        \n",
    "        self.keystroke_params = list(self.user.keystroke_train_test_data())\n",
    "        self.keystrokeLearningModel = KeystrokeLearningModel(*self.keystroke_params)\n",
    "        \n",
    "        self.mouseResult = None\n",
    "        self.keystrokeResult = None\n",
    "        \n",
    "\n",
    "    def train_mouseModel(self):\n",
    "        optimal_models = self.mouseLearningModel.optimal_models()\n",
    "        self.mouseLearningModel.approximate_cutoffs(optimal_models)\n",
    "        return self.mouseLearningModel.train()\n",
    "    \n",
    "    def test_mouseModel(self, ideal_cutoff=10):\n",
    "        self.mouseLearningModel.ideal_cutoff = ideal_cutoff\n",
    "        res = self.mouseLearningModel.test()\n",
    "        self.mouseResult = res\n",
    "        return res\n",
    "    \n",
    "    def train_keystrokeModel(self):\n",
    "        optimal_models = self.keystrokeLearningModel.optimal_models()\n",
    "        return self.keystrokeLearningModel.train()\n",
    "\n",
    "    def test_keystrokeModel(self, ideal_cutoff=9, display_predictions=False):\n",
    "        res = self.keystrokeLearningModel.test(ideal_cutoff=ideal_cutoff, display_prediction=display_predictions)\n",
    "        self.keystrokeResult = res\n",
    "        return res\n",
    "    \n",
    "    def combined_score(self):\n",
    "        return self.keystrokeResult[0]+self.mouseResult[0]\n",
    "    \n",
    "    def combined_summary(self, cutoff=20):\n",
    "        combined_score = self.combined_score()\n",
    "        prediction = np.where(combined_score >= cutoff, 1, 0)\n",
    "        \n",
    "        return combined_score, classifier_summary(self.mouseLearningModel.Y_test, prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:DATA:Selected classes [51  4]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([22,  6,  1,  6, 22,  0, 22, 22, 22,  1]), [0.0, 0.0, 1.0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authenticator = Authenticator(13, sessions, classes=2)\n",
    "\n",
    "authenticator.train_mouseModel()\n",
    "authenticator.train_keystrokeModel()\n",
    "\n",
    "authenticator.test_keystrokeModel()\n",
    "authenticator.test_mouseModel()\n",
    "\n",
    "authenticator.combined_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of changing number of classes in the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select five classes at random\n",
    "import random\n",
    "random_classes = random.choices(range(1,51), k=10)\n",
    "changing_number_of_classes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:DATA:Selected classes [35 36]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [11 40]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [22 39]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [43 37]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [24 33]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [20  7]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [ 8 16]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [31 53]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [ 5 39]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [20 36]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [40 31 49 16 35  3 38 24  9 52]\n",
      "INFO:LEARNING:Running SVC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [50 48  9  7 12 15 13 49 16 20]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [39 14 18 11  7 38 45 36 55 15]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [ 7 44 28  3 15 34  8 27 54 18]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [17 48  8 21 10  4  3  1 38 53]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [54 15 18  4  5 42 28 20 55 53]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [51 27 12 54 30 37 32 48 50 26]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [43 18 36 22 19  8 41 52 26 44]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [40 50 31 36  2 12 39 13 14 23]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [49 12 25 51 22  1 14 26 28 52]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [ 8 11 48 37 47 41 40 43 53 55 23 34 25 32  3 17 54 33 12 13]\n",
      "INFO:LEARNING:Running SVC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [36 15 14 17 13 47 21 42 45 35 51 48 39 54 38  1 25  2 33  3]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [10  9 36 22 47 38 17 33 11 41 44  5 37 43 50 21 24 55 49  6]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [48 25  8  7 51 43 53 13  6 50 33  3  9 45 38  5 54 55 34 26]\n",
      "INFO:LEARNING:Running SVC\n",
      "INFO:LEARNING:Running AdaBoostClassifier\n",
      "INFO:LEARNING:Running GaussianNB\n",
      "INFO:LEARNING:Running RandomForestClassifier\n",
      "INFO:LEARNING:Running BernoulliNB\n",
      "INFO:LEARNING:Running MultinomialNB\n",
      "INFO:LEARNING:Running SGDClassifier\n",
      "INFO:LEARNING:Running MLPClassifier\n",
      "INFO:DATA:Selected classes [44 39 22 14 16 18 43  9 12 40 13  8 26 28  2 50 34 25  5 42]\n",
      "INFO:LEARNING:Running SVC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-0152be389dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mauthenticator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAuthenticator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mauthenticator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mouseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmouse_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthenticator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mouseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-766b3fe4484f>\u001b[0m in \u001b[0;36mtrain_mouseModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_mouseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptimal_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouseLearningModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimal_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouseLearningModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproximate_cutoffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouseLearningModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9f12994a412d>\u001b[0m in \u001b[0;36moptimal_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m                             \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                         \u001b[0mvalidation_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_validation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keyboard_performance = []\n",
    "mouse_performance = []\n",
    "combined_performance = []\n",
    "classes = [2, 10, 20, 30, 40, 50]\n",
    "for _classes in classes:\n",
    "    print(_classes)\n",
    "    for each in random_classes:\n",
    "        authenticator = Authenticator(each, sessions, classes=_classes, instances=10)\n",
    "\n",
    "        authenticator.train_mouseModel()\n",
    "        mouse_performance.append(authenticator.test_mouseModel()[-1])\n",
    "\n",
    "        authenticator.train_keystrokeModel()\n",
    "        keyboard_performance.append(authenticator.test_keystrokeModel()[-1])\n",
    "\n",
    "        combined_performance.append(authenticator.combined_summary()[-1])\n",
    "    changing_number_of_classes[_classes] = (np.array(keyboard_performance),\n",
    "                                           np.array(mouse_performance),\n",
    "                                           np.array(combined_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: (array([[0.3       , 0.        , 0.8       ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.2       , 0.2       , 0.8       ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.2       , 0.4       , 0.73333333],\n",
       "         [0.        , 0.2       , 0.93333333],\n",
       "         [0.1       , 0.2       , 0.86666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.4       , 0.        , 0.73333333],\n",
       "         [0.2       , 0.4       , 0.73333333]]),\n",
       "  array([[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.6       , 0.8       ],\n",
       "         [0.        , 0.4       , 0.86666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.5       , 0.        , 0.66666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 1.        , 0.66666667]]),\n",
       "  array([[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.2       , 0.93333333],\n",
       "         [0.        , 0.2       , 0.93333333],\n",
       "         [0.        , 0.4       , 0.86666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.1       , 1.        , 0.6       ]])),\n",
       " 10: (array([[0.3       , 0.        , 0.8       ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.2       , 0.2       , 0.8       ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.2       , 0.4       , 0.73333333],\n",
       "         [0.        , 0.2       , 0.93333333],\n",
       "         [0.1       , 0.2       , 0.86666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.4       , 0.        , 0.73333333],\n",
       "         [0.2       , 0.4       , 0.73333333],\n",
       "         [0.26      , 0.6       , 0.70909091],\n",
       "         [0.        , 0.6       , 0.94545455],\n",
       "         [0.02      , 0.        , 0.98181818],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.04      , 0.8       , 0.89090909],\n",
       "         [0.02      , 0.8       , 0.90909091],\n",
       "         [0.        , 0.8       , 0.92727273],\n",
       "         [0.12      , 0.        , 0.89090909],\n",
       "         [0.        , 0.8       , 0.92727273],\n",
       "         [0.        , 0.8       , 0.92727273]]),\n",
       "  array([[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.6       , 0.8       ],\n",
       "         [0.        , 0.4       , 0.86666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.5       , 0.        , 0.66666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 1.        , 0.66666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.2       , 0.98181818],\n",
       "         [0.02      , 0.8       , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.02      , 0.8       , 0.90909091],\n",
       "         [0.1       , 0.4       , 0.87272727],\n",
       "         [0.02      , 1.        , 0.89090909]]),\n",
       "  array([[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.2       , 0.93333333],\n",
       "         [0.        , 0.2       , 0.93333333],\n",
       "         [0.        , 0.4       , 0.86666667],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.1       , 1.        , 0.6       ],\n",
       "         [0.        , 0.6       , 0.94545455],\n",
       "         [0.        , 0.4       , 0.96363636],\n",
       "         [0.02      , 0.2       , 0.96363636],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.        , 1.        , 0.90909091],\n",
       "         [0.02      , 0.4       , 0.94545455],\n",
       "         [0.        , 0.8       , 0.92727273],\n",
       "         [0.        , 1.        , 0.90909091]]))}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changing_number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.32, 0.88])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(combined_performance), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of changing number of hidden classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curves for \n",
    "### 1. Mouse\n",
    "### 2. Keystroke\n",
    "### 3. Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystroke = []\n",
    "mouse = []\n",
    "combined = []\n",
    "for i in range(1,5):\n",
    "    authenticator = Authenticator(i, sessions, classes=30, test_size=(0.20, 0.5), instances=10)\n",
    "\n",
    "    _= authenticator.train_mouseModel()\n",
    "    _= authenticator.train_keystrokeModel()\n",
    "\n",
    "    res = []\n",
    "    for cutoff in range(1,13):\n",
    "        authenticator.test_mouseModel(ideal_cutoff=cutoff)\n",
    "        res.append(authenticator.mouseResult[1][0:-1])\n",
    "    res = np.array(res)\n",
    "    mouse.append(res)\n",
    "    res = []\n",
    "    for cutoff in range(1,13):\n",
    "        authenticator.test_keystrokeModel(ideal_cutoff=cutoff)\n",
    "        res.append(authenticator.keystrokeResult[1][0:-1])\n",
    "    res = np.array(res)\n",
    "    keystroke.append(res)\n",
    "    res = []\n",
    "    for cutoff in range(15,21):\n",
    "        res.append(authenticator.combined_summary(cutoff=cutoff)[1][0:-1])\n",
    "    res = np.array(res)\n",
    "    combined.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.xlabel('False Acceptance Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "for each in np.array(mouse):\n",
    "    plt.plot(each[:,0], 1-each[:,1], linewidth=2)\n",
    "    plt.pause(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel:\n",
    "    def __init__(self, userid, sessions):\n",
    "        \"\"\"\n",
    "        Initiate the UserModel object with sessions divided into different sets\n",
    "        \"\"\"\n",
    "        self.userid = userid\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "        self.X_test = None\n",
    "        self.Y_test = None\n",
    "\n",
    "        self.SessionsX= []\n",
    "        self.SessionsY = []\n",
    "        self.othersSessionsX= []\n",
    "        self.othersSessionsY= []\n",
    "        \n",
    "        self.seenUsers = None\n",
    "        \n",
    "        for session in sessions: #dataX is a collection of users\n",
    "            if session.userid == self.userid:\n",
    "                self.SessionsX.append(session)\n",
    "                self.SessionsY.append(self.userid)\n",
    "            else:\n",
    "                self.othersSessionsX.append(session)\n",
    "                self.othersSessionsY.append(session.userid)\n",
    "                    \n",
    "                    \n",
    "        self.meanMouseLength = int(np.mean([len(_.mouseLog) for _ in self.SessionsX]))\n",
    "        self.stdMouseLength = int(np.std([len(_.mouseLog) for _ in self.SessionsX]))\n",
    "        \n",
    "        self.SessionsX, self.SessionsY, self.othersSessionsX, self.othersSessionsY = \\\n",
    "            np.array(self.SessionsX), np.array(self.SessionsY), np.array(self.othersSessionsX), np.array(self.othersSessionsY)\n",
    "        \n",
    "    def train_test_data(self, \n",
    "                        test_size=(0.20, 0.50), \n",
    "                        classes=0, \n",
    "                        binary_classes=False, \n",
    "                        instances=5, \n",
    "                        random=3):\n",
    "        \"\"\"\n",
    "        Return and set training and test dataset for self\n",
    "        \n",
    "        Keyword Arguments:\n",
    "        test_size (float, float): test size for splitting the dataset of self vs other classes.\n",
    "        classes (int): Number of other user User(s) to consider.\n",
    "        instances (int): Number of examples to take from the considered classes.\n",
    "        \n",
    "        \"\"\"     \n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = \\\n",
    "            train_test_split(self.SessionsX, self.SessionsY, test_size=test_size[0], random_state=random)\n",
    "        \n",
    "        if classes == 0:\n",
    "            self.X_train, self.X_test, self.Y_train, self.Y_test = \\\n",
    "                X_train, X_test, Y_train, Y_test\n",
    "            \n",
    "        elif classes > 0:\n",
    "            assert instances <= 25, \"Too many instances requested\"\n",
    "            other_classes = np.unique(self.othersSessionsY[self.othersSessionsY != self.userid])\n",
    "            assert len(other_classes) >= classes, \"Too many classes\"\n",
    "            \n",
    "            np.random.shuffle(other_classes)\n",
    "            other_classes = other_classes[:classes]\n",
    "            self.seenUsers = other_classes\n",
    "            \n",
    "            data_logger.info(\"Selected classes \"+str(other_classes))\n",
    "            \n",
    "            dataX = []\n",
    "            dataY = []\n",
    "\n",
    "            for each in other_classes:\n",
    "                for session in self.othersSessionsX[self.othersSessionsY == each][:instances]:\n",
    "                    dataX.append(session)\n",
    "                    if binary_classes:\n",
    "                        dataY.append(-1)\n",
    "                    else:\n",
    "                        dataY.append(each)\n",
    "\n",
    "            X_train_other, X_test_other, Y_train_other, Y_test_other = \\\n",
    "                train_test_split(np.array(dataX), np.array(dataY), test_size=test_size[1], random_state=random)\n",
    "\n",
    "            self.X_train = np.concatenate((X_train, X_train_other), axis=0)\n",
    "            self.X_test = np.concatenate((X_test, X_test_other), axis=0)\n",
    "            self.Y_train = np.concatenate((Y_train, Y_train_other), axis=0)\n",
    "            self.Y_test = np.concatenate((Y_test, Y_test_other), axis=0)\n",
    "        \n",
    "            #Shuffle the data rows\n",
    "            assert len(self.X_test) == len(self.Y_test)\n",
    "            p = np.random.permutation(len(self.X_test))\n",
    "            self.X_test = self.X_test[p]\n",
    "            self.Y_test = self.Y_test[p]\n",
    "            \n",
    "        \n",
    "        return self.X_train, self.X_test, self.Y_train, self.Y_test #other_classes\n",
    "    \n",
    "    def mouse_train_test_data(self, binary_classes=True):\n",
    "        \"\"\"\n",
    "        Return and set training and test dataset for self\n",
    "        \"\"\"     \n",
    "        assert all([not each is None for each in [self.X_train,\n",
    "                                             self.X_test,\n",
    "                                             self.Y_train,\n",
    "                                             self.Y_test]]), \"Run train_test_data first\"\n",
    "        \n",
    "        X_train = np.array([session.mouseLog for session in self.X_train])\n",
    "        X_test = np.array([session.mouseLog for session in self.X_test])\n",
    "        Y_train = self.Y_train.copy()\n",
    "        Y_test = self.Y_test.copy()\n",
    "        \n",
    "        if binary_classes:\n",
    "            Y_train = np.where(Y_train == self.userid, 1, 0)\n",
    "            Y_test = np.where(Y_test == self.userid, 1, 0)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    def keystroke_train_test_data(self, binary_classes=True):\n",
    "        assert all([not each is None for each in [self.X_train,\n",
    "                                     self.X_test,\n",
    "                                     self.Y_train,\n",
    "                                     self.Y_test]]), \"Run train_test_data first\"\n",
    "        \n",
    "        X_train = np.array([session.keystrokeLog for session in self.X_train])\n",
    "        X_test = np.array([session.keystrokeLog for session in self.X_test])\n",
    "        Y_train = self.Y_train.copy()\n",
    "        Y_test = self.Y_test.copy()\n",
    "\n",
    "        if binary_classes:\n",
    "            Y_train = np.where(Y_train == self.userid, 1, 0)\n",
    "            Y_test = np.where(Y_test == self.userid, 1, 0)\n",
    "        \n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Session:\n",
    "    def __init__(self, userid, mouseLog, keystrokeLog):\n",
    "        self.userid = userid\n",
    "        self.mouseLog = mouseLog\n",
    "        self.keystrokeLog = keystrokeLog\n",
    "        \n",
    "min_sessions = 25\n",
    "sessions = []\n",
    "for _, user in enumerate(valid_participants):\n",
    "    user_sessions = []\n",
    "    for session in user:   \n",
    "        mouseLog = np.array(session['mouseLogs'][0], dtype='int32') \n",
    "        keyLog = np.array(list(map(lambda x: x['duration'], session['passwordLogs']+session['usernameLogs'])), dtype='int32') \n",
    "        \n",
    "        if len(mouseLog) and len(keyLog):\n",
    "            user_sessions.append(Session(_+1, mouseLog, keyLog))\n",
    "        \n",
    "    if len(user_sessions) >= min_sessions:\n",
    "        sessions += user_sessions[-1*min_sessions:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('valid_participants', 'rb') as f:\n",
    "#     try:\n",
    "#         pickle.load(f)\n",
    "#     except:\n",
    "#         return \"It seems you did't dump the dataset in the first place\"\n",
    "#     return pickle.load(f)\n",
    "        \n",
    "\n",
    "with open('valid_participants', 'wb') as f:\n",
    "    pickle.dump(sessions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
